## UMIS: Trusworthy medical image segmentation
Conference version of 
[TBraTS: Trusted Brain Tumor Segmentation](https://arxiv.org/abs/2206.09309)

## Requirements
Some important required packages include:  
Pytorch version >=0.4.1.  
Visdom  
Python == 3.7  
Some basic python packages such as Numpy.  

## Introduction
Medical image segmentation (MIS) is essential for supporting disease diagnosis and treatment effect assessment. Despite considerable advances in artificial intelligence (AI) for MIS, clinicians remain skeptical of its utility, maintaining low confidence in such black box systems, with this problem being exacerbated by low generalization for out-of-distribution (OOD) data. To move towards effective clinical utilization, we propose a foundation model named EvidenceCap, which makes the box transparent in a quantifiable way by uncertainty estimation. EvidenceCap not only makes AI visible in regions of uncertainty and OOD data, but also enhances the reliability, robustness, and computational efficiency of MIS. Uncertainty is modeled explicitly through subjective logic theory to gather strong evidence from features. We show the effectiveness of EvidenceCap in three segmentation datasets and apply it to the clinic. Our work sheds light on clinical safe applications and explainable AI, and can contribute towards trustworthiness in the medical domain.

<div align=center><img width="900" height="400" alt="Our TBraTS framework" src="https://github.com/Cocofeat/UMIS/blob/main/image/Moti-TMIS.pdf"/></div>
<div align=center><img width="900" height="400" alt="Our TBraTS framework" src="https://github.com/Cocofeat/UMIS/blob/main/image/NC_F1.pdf"/></div>

##  :fire: NEWS :fire:
* [09/17] We will release the code as soon as possible. 
